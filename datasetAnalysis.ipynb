{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = './dataset/dataset2.csv'\n",
    "\n",
    "with open (file_path, 'r', encoding='latin1') as file:\n",
    "    text = file.read()\n",
    "\n",
    "###     \n",
    "### carico il dataset dal file originale e faccio un processo di encoding e decoding da utf-8 per eliminare i caratteri speciali\n",
    "###\n",
    "text = text.replace('\\x92', \"'\")\n",
    "with open('./dataset/editato.csv', 'w', encoding='utf-8') as file2:\n",
    "    file2.write(text.encode(encoding='utf-8').decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 259569 entries, 0 to 259568\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   tweet_date_created  259569 non-null  object\n",
      " 1   tweet_id            259569 non-null  int64 \n",
      " 2   tweet_text          259569 non-null  object\n",
      " 3   language            259569 non-null  object\n",
      " 4   sentiment           259569 non-null  object\n",
      " 5   sentiment_score     259569 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./dataset/editato.csv', encoding='utf-8')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di elementi con sentimento Neutral più alto: 226868\n",
      "Numero di elementi con sentimento Negative più alto: 9441\n",
      "Numero di elementi con sentimento Positive più alto: 22883\n",
      "Numero di elementi con sentimento Mixed più alto: 377\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Numero di elementi con sentimento Neutral più alto:\", sentiment_counts['NEUTRAL'])\n",
    "print(\"Numero di elementi con sentimento Negative più alto:\", sentiment_counts['NEGATIVE'])\n",
    "print(\"Numero di elementi con sentimento Positive più alto:\", sentiment_counts['POSITIVE'])\n",
    "print(\"Numero di elementi con sentimento Mixed più alto:\", sentiment_counts['MIXED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def rimuovi_mentions_hashtag_e_link(testo):\n",
    "    return re.sub(r'(@[\\w\\d]+|#[\\w\\d]+|https://t\\.co/[\\w\\d]+)', '', testo)\n",
    "\n",
    "def rimuovi_punteggiatura(testo):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', testo.lower())\n",
    "\n",
    "\n",
    "# Applica la funzione a ciascuna riga della colonna 'tweet_text'\n",
    "df['tweet_text'] = df['tweet_text'].apply(rimuovi_mentions_hashtag_e_link)\n",
    "df['tweet_text'] = df['tweet_text'].apply(rimuovi_punteggiatura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\selector_events.py\", line 115, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] Connessione in corso interrotta forzatamente dall'host remoto\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\giova\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\selector_events.py\", line 115, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "ConnectionResetError: [WinError 10054] Connessione in corso interrotta forzatamente dall'host remoto\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "preposizioni_articolate = [\n",
    "    \"al\", \"allo\", \"alla\", \"ai\", \"agli\", \"alla\",\n",
    "    \"del\", \"dello\", \"della\", \"dei\", \"degli\", \"delle\",\n",
    "    \"nel\", \"nello\", \"nella\", \"nei\", \"negli\", \"nelle\",\n",
    "    \"sul\", \"sullo\", \"sulla\", \"sui\", \"sugli\", \"sulle\",\n",
    "    \"col\", \"collo\", \"colla\", \"coi\", \"cogli\", \"colle\",\n",
    "    \"dal\", \"dallo\", \"dalla\", \"dai\", \"dagli\", \"dalle\",\n",
    "    \"nel\", \"nello\", \"nella\", \"nei\", \"negli\", \"nelle\",\n",
    "    \"pel\", \"pello\", \"pella\", \"pei\", \"pegli\", \"pelle\",\n",
    "    \"sul\", \"sullo\", \"sulla\", \"sui\", \"sugli\", \"sulle\",\n",
    "    \"con\",\"d\",\"c\",\"l\"\n",
    "]\n",
    "stop_words.update(preposizioni_articolate)\n",
    "\n",
    "def tokenizza_testo(testo):\n",
    "    return word_tokenize(testo)\n",
    "\n",
    "def lemmatizza_testo(parole_tokenizzate):\n",
    "    parole_lemmatizzate = []\n",
    "    for token in nlp(\" \".join(parole_tokenizzate)):\n",
    "        if token.lemma_.lower() not in stop_words:\n",
    "            parole_lemmatizzate.append(token.lemma_)\n",
    "    return parole_lemmatizzate\n",
    "\n",
    "def rimuovi_stop_words(parole):\n",
    "    return [parola for parola in parole if parola.lower() not in stop_words]\n",
    "\n",
    "\n",
    "\n",
    "def processa_testo(testo):\n",
    "    parole_tokenizzate = tokenizza_testo(testo)\n",
    "    parole_pulite = rimuovi_stop_words(parole_tokenizzate)\n",
    "    parole_lemmatizzate = lemmatizza_testo(parole_pulite)\n",
    "    return parole_lemmatizzate\n",
    "\n",
    "\n",
    "df['processed_text'] = df['tweet_text'].apply(processa_testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvataggio del dataset ottenuto dalla fase di preprocessing in un file csv\n",
    "df.to_csv('./dataset/processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed.csv')\n",
    "\n",
    "df = df[['processed_text', 'sentiment']]\n",
    "\n",
    "df['processed_text'] = df['processed_text'].apply(lambda x: x.replace('[','').replace(']','').replace(',','').replace(\"'\",''))\n",
    "\n",
    "df.to_csv('./dataset/testo_e_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('testo_e_sentiment.csv')\n",
    "num_negative = (df['sentiment'] == 'NEGATIVE').sum()\n",
    "\n",
    "undersampled_df = pd.concat([\n",
    "    df[df['sentiment'] == 'NEGATIVE'],  \n",
    "    df[df['sentiment'] == 'POSITIVE'].sample(n=num_negative, random_state=42),  \n",
    "    df[df['sentiment'] == 'NEUTRAL'].sample(n=num_negative, random_state=42) \n",
    "])\n",
    "\n",
    "undersampled_df = undersampled_df.sample(frac=1, random_state=42)\n",
    "\n",
    "print(undersampled_df['sentiment'].value_counts())\n",
    "\n",
    "undersampled_df.to_csv('./dataset/undersampled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
